{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSwXc30HMzT5",
        "colab_type": "text"
      },
      "source": [
        "## Create the necessary imports\n",
        "- Tensorflow which is a deep learning framework (uses Keras for cerating neural networks).\n",
        "- Tensorboard will help us to visuaize the model key values like accuracy or loss. It can help debugging the neural network because we can prevent model memorizing.\n",
        "- Numpy for high performance matrix manipulation.\n",
        "- Random for generating a random seed.\n",
        "- Matplotlib for plotting data and doing a visual exploration.\n",
        "- mlxtend.plotting for the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CXoMGZfMt9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IklbfTte54OO",
        "colab_type": "text"
      },
      "source": [
        "## Install the tunneling tool.\n",
        "- This will allow us to follow the statistics of our model just by clicking in the link provided above.\n",
        "- The statistics used are provided by Tensorboard.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O1Ng-UC53Xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S47ZPMMNMu6O",
        "colab_type": "text"
      },
      "source": [
        "## Download the data from MNIST\n",
        "- Note that in this case Keras can import the data just with a single sentence, as this dataset is considered the hello word of deep learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv3oTuYXNBMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPB76KvmNFJ1",
        "colab_type": "text"
      },
      "source": [
        "## Separe the dataset into training and test\n",
        "- Note that in this case the data is already separed just by executing the load_data() method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1N_8DLeNO4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train),(X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9duCmsCIOfS1",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess the data:\n",
        "- As we are working with images, and the pixels from the images are represented in the RGB standard, it can have a value from 0 to 255. But as we remember, we like to standarize the data to convert the values from 0 to 1, in order to improve the neural network performance.\n",
        "- Check the frequency of the classes\n",
        "- Do an exploration of the data we are using. We observe that at least to the human eye it's possible to distinguish the number after reducing the image to a 28x28 pixels image, despite of the resolution loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G2W8GNpPRXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "# Test the size of the training and test set\n",
        "print('Train size: {} , Test size: {}'.format(len(X_train), len(X_test)))\n",
        "\n",
        "# Test the frequency of the training set to detect if it was necessary to stratify.\n",
        "x = np.random.randint(1, 100, 5)\n",
        "plt.hist(np.array(y_train), bins=10)\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Test just a random image to see what we are working with:\n",
        "random_sample = random.randint(0, len(X_test)-1)\n",
        "label, pixels =  y_train[random_sample], X_train[random_sample]\n",
        "img = np.array(pixels).reshape((28,28))\n",
        "print('Label: {}'.format(label))\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUOyGAIzlavF",
        "colab_type": "text"
      },
      "source": [
        "## Choose the model we are using to train our dataset\n",
        "- We create a Sequential model, meaning that we build our networks as layers. For that we pass an array with the list of layers and sublayers to execute.\n",
        "- A model needs an optimizer, in order to set some parameters like the learning rate. A too high learning ratio could hinder convergence, and limit the accuracy of our model. Adam is an optimization algorithm, very much used in neural networks, but we could use another or even our own configuration.\n",
        "- Cross entropy is a metric that can be used to reflect the accuracy of probabilistic predictions. In this case we use sparse because we have more than two classes.\n",
        "- The activation function defines the kind of output when the neuron compares it's output to the threshold. For example, Relu will create outputs either zero or a lineal function.\n",
        "- The first we note is the Flatten layer. This is working as numpy.reshape works, that is giving a new shape to the image without changing its data. We choosed images of 28x28 based on the intuition that we can identify the image plotten.\n",
        "- The next is a Dense layer, with is a regular neural network layer. About the number of nodes to choose is based on a test. We can define variables to iterate over in order to define the best combination between number of hidden layers and the number of nodes per layer. About why the number of layers is a power of two, is just a convention, it just could be 511 instead of 512.\n",
        "- The dropout is a process to prevent the overfitting by setting to zero a percentage of inputs choosen randomly. It's  a not really intuitive technique that actually gives good results.\n",
        "- The last layer has to have an exact number of neurons, the number classification we want to obtain. Of course if we want to increase the number of sub-layers before arriving to this point, we can do it, in that case we are free to define the number of neurons we get the best result as soon as we respect that the last layer has to have te exact number of neurons that the number of classes we have.\n",
        "- Five epochs have been enought to obtain up to 96% accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STsyZ82wdmoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard = TensorBoard('./log')\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(X_train, y_train, epochs=5, callbacks=[tensorboard])\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ncZWCUY-F5b",
        "colab_type": "text"
      },
      "source": [
        "## Test the results with a random image from the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVKiF2RM5QBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = random.randint(0, len(X_test)-1)\n",
        "size_i = len(X_test[seed])\n",
        "print(size_i)\n",
        "test_img = np.array([X_test[seed].reshape((28,28))])\n",
        "\n",
        "predictions = model.predict(test_img)\n",
        "accuracy = np.amax(predictions) * 100\n",
        "\n",
        "prediction = np.unravel_index(predictions.argmax(), predictions.shape[1])[0]\n",
        "print('Prediction: {} - Accuracy {}% - Ground Truth {}'.format(prediction, round(accuracy,2), y_test[seed]))\n",
        "\n",
        "img = np.array(test_img).reshape((28,28))\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld2MJImJiPB6",
        "colab_type": "text"
      },
      "source": [
        "## Let's plot the results in a confusion matrix\n",
        "Now if we are interested in knowing the prediction versus the real value of all the test examples, not just a single one as we saw, we can build a confusion matrix to plot them all.\n",
        "- First we obtain the predictions over the X_test examples.\n",
        "- Then, we pre-process the results obtained in order to plt the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAbi8AcYh5Bk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = []\n",
        "\n",
        "predictions_test = model.predict(X_test)\n",
        "\n",
        "for prediction in predictions_test:\n",
        "  y = prediction.argmax()\n",
        "  y_pred.append(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP3gcNfCh9TG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sumarize = {}\n",
        "for t in range(0, 10):\n",
        "  sum_pred = {}\n",
        "  \n",
        "  for p in range(0, 10):\n",
        "    sum_pred[p] = 0\n",
        "  \n",
        "  sumarize[t] = sum_pred\n",
        "\n",
        "for i, t in enumerate(y_test):\n",
        "  sumarize[t][y_pred[i]] = sumarize[t][y_pred[i]] + 1\n",
        "  \n",
        "\n",
        "sum_array = []\n",
        "for label in sumarize.values():\n",
        "  values = []\n",
        "  for result in label.values():\n",
        "    values.append(result)\n",
        "  sum_array.append(values)\n",
        "\n",
        "plot_confusion_matrix(conf_mat=np.array(sum_array),\n",
        "                      show_absolute=True,\n",
        "                      show_normed=False,\n",
        "                      colorbar=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}